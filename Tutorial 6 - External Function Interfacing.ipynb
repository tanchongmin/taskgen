{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa1e388-b8f4-4fa3-be5a-ba7c6caae038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 6 - External Function Interfacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75f665-03e3-48d9-bc70-fab5f0549424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install taskgen-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076adf5e-beb1-4b19-9078-34ab1b7d9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up API key and do the necessary imports\n",
    "import os\n",
    "from taskgen import *\n",
    "import random\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b9a5f-7e80-4a03-a822-8135b1f8da3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding Python Function directly to Function\n",
    "- You should write a docstring that describes the function and contains all the input variable names that are not `args`, `kwargs` or `shared_variables`\n",
    "- typing for inputs and outputs will be automatically converted to TaskGen `Function` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed33cbb-bc0e-45ca-b06b-68cdeb50a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\n",
    "    ''' Appends num1 to num_list '''\n",
    "    num_list.append(num1)\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca759a1-49bf-4d96-9494-f387c9526256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = Function(external_fn = add_number_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23d77ff-fd6d-4668-85a1-450278c881aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Appends <num1: int> to <num_list: list[int]> \n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'output_1': 'list[int]'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367956e-916b-441c-906c-892090eee051",
   "metadata": {},
   "source": [
    "# Adding Python Function directly to Agent\n",
    "- We can also assign the Python function directly to an Agent and it will automatically convert it to `Function` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e6c470-92a6-4fe1-8370-a9c74c1cf390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Math Whiz', 'Does Math Calculations').assign_functions([add_number_to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3b6747-64a5-4e9e-858c-cddd5e0de689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: For general tasks. Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only after task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add_number_to_list\\nDescription:  Appends <num1: int> to <num_list: list[int]> \\nInput: ['num1', 'num_list']\\nOutput: {'output_1': 'list[int]'}\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5238a9a6-a654-482c-811a-0f4c8d21f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Need to append 5 to [2, 4]\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Append 5 to [2, 4]\u001b[0m\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task is to append 5 to the list [2, 4]\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The task has been partially completed by adding 5 to the list [2, 4]. To complete the task, we need to use the \"add_number_to_list\" function to append 5 to the list.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Append 5 to the list [2, 4]\u001b[0m\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task is to append 5 to the list [2, 4]. Two subtasks have been completed successfully, resulting in the list [2, 4, 5].\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The task has been completed successfully with the previous subtasks. No further action is needed. It is time to end the task.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': [2, 4, 5]}, {'output_1': [2, 4, 5]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Append 5 to [2, 4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6a7b7-2fdb-407e-bd5c-3024c007a8a5",
   "metadata": {},
   "source": [
    "# CrewAI Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8455989c-b934-49ee-aaed-e3562002722a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b93ebcb-022b-482a-8a2c-184e208402e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c37c1b-439b-4948-ba2b-e1266e394a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# just wrap the external tool within a function\n",
    "def scrape_website_tool(website_url: str) -> str:\n",
    "    ''' Scrapes data from website_url '''\n",
    "    # import the tool\n",
    "    from crewai_tools import ScrapeWebsiteTool\n",
    "    \n",
    "    # initialise the tool\n",
    "    docs_scrape_tool = ScrapeWebsiteTool(\n",
    "        website_url=website_url)\n",
    "    \n",
    "    # run the tool\n",
    "    return docs_scrape_tool.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74d03606-5399-4056-9ed2-d8c7e6a262f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Website summariser', 'Scrapes and then uses LLM to summarise a website to the user', model = 'gpt-4o').assign_functions([scrape_website_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3605667-a7de-4051-918a-8d32cb008d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: use_llm\n",
      "Description: For general tasks. Used only when no other function can do the task\n",
      "Input: []\n",
      "Output: {'Output': 'Output of LLM'}\n",
      "\n",
      "Name: end_task\n",
      "Description: Use only after task is completed\n",
      "Input: []\n",
      "Output: {}\n",
      "\n",
      "Name: scrape_website_tool\n",
      "Description:  Scrapes data from <website_url: str> \n",
      "Input: ['website_url']\n",
      "Output: {'output_1': 'str'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c23c8d1-0b4e-40d7-9dfd-12c69ac16016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To determine the differences between TaskGen and CrewAI, I need to scrape the content from both websites. First, I will scrape the TaskGen website, and then I will scrape the CrewAI website. After gathering the data, I will use the LLM to summarize and compare the information.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Scrape data from the TaskGen website at 'https://github.com/simbianai/taskgen'.\u001b[0m\n",
      "Calling function scrape_website_tool with parameters {'website_url': 'https://github.com/simbianai/taskgen'}\n",
      "Using Tool: Read website content\n",
      "> {'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n simbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n 10\\n Star\\n 75\\n Task-based Agentic Framework using StrictJSON as the core\\nLicense\\n MIT license\\n75\\n stars\\n10\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History92 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_07May2024.ipynbTaskGen AMA_07May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.1.1\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion\\nfn_name - String. If provided, this will be the name of the function. Ohterwise, if external_fn is provided, it will be the name of external_fn. Otherwise, we will use LLM to generate a function name from the fn_description\\nkwargs - Dict. Additional arguments you would like to pass on to the strict_json function\\nOutputs:\\nJSON of output variables in a dictionary (similar to strict_json)\\nExample Internal LLM-Based Function\\n# Construct the function: var1 will be first input variable, var2 will be second input variable and so on\\nsentence_style = Function(fn_description = \\'Output a sentence with words <var1> and <var2> in the style of <var3>\\', output_format = {\\'output\\': \\'sentence\\'})\\n# Use the function\\nsentence_style(\\'ball\\', \\'dog\\', \\'happy\\') #var1, var2, var3\\nExample Output\\n{\\'output\\': \\'The happy dog chased the ball.\\'}\\nExample External Function\\ndef binary_to_decimal(x):\\n return int(str(x), 2)\\n# an external function with a single output variable, with an expressive variable description\\nb2d = Function(fn_description = \\'Convert input <x: a binary number in base 2> to base 10\\', output_format = {\\'output1\\': \\'x in base 10\\'},\\n external_fn = binary_to_decimal)\\n# Use the function\\nb2d(10) #x\\nExample Output\\n{\\'output1\\': 2}\\nExample fn_description inferred from type hints and docstring of External Function\\n# Docstring must provide all input variables\\n# We will ignore shared_variables, *args and **kwargs\\nfrom typing import List\\ndef add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\\n \\'\\'\\'Adds num1 to num_list\\'\\'\\'\\n num_list.append(num1)\\n return num_list\\nfn = Function(external_fn = add_number_to_list, #output_format = {\\'num_array\\': \\'Array of numbers\\'} ## If you would like to name output variables (helps with LLM understanding), define your own output_format\\n )\\nstr(fn)\\nExample Output\\nDescription: Adds Adds <num1: int> to <num_list: list[int]>\\nInput: [\\'num1\\', \\'num_list\\']\\nOutput: {\\'output_1\\': \\'list[int]\\'}\\nPower Up your Agents - Bring in Functions (aka Tools)\\nAfter creating your agent, use assign_functions to assign a list of functions (of class Function) to it\\nFunction names will be automatically inferred if not specified\\nProceed to run tasks by using run()\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nmy_agent.assign_functions([sentence_style, b2d])\\noutput = my_agent.run(\\'Generate me a happy sentence with a number and a ball. The number is 1001 converted to decimal\\')\\nSubtask identified: Convert the binary number 1001 to decimal\\nCalling function binary_to_decimal with parameters {\\'x\\': \\'1001\\'}\\n{\\'output1\\': 9}\\nSubtask identified: Generate a happy sentence with the decimal number and a ball\\nCalling function sentence_with_objects_entities_emotion with parameters {\\'obj\\': \\'9\\', \\'entity\\': \\'ball\\', \\'emotion\\': \\'happy\\'}\\n{\\'output\\': \\'I am so happy with my 9 balls.\\'}\\nTask completed successfully!\\nSaving and Loading Agents\\nSometimes you want to configure your agents and save them and load them elsewhere, while maintaining the current agent state\\nWhen you use the save_agent function, we store the entire agent\\'s internal state, include name, description, list of functions, subtasks history and all other internal variables into a pickle file\\nWhen you use the load_agent function, and we will load the entire agent saved in the pickle file into the existing agent\\nKey functions:\\nsave_agent(pickle_file_name: str): Saves the agent\\'s internal parameters to a pickle file named pickle_file_name (include .pkl), returns the pickle file\\nload_agent(pickle_file_name: str): Loads the agent\\'s internal parameters from a pickle file named pickle_file_name (include .pkl), returns loaded agent\\nExample 1: Saving Agent\\nmy_agent.save_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent saved to myagent.pkl\\nExample 2: Loading Agent\\nnew_agent = Agent().load_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent loaded from myagent.pkl\\nInception: Agents within Agents - See Tutorial 2\\nYou can also create a Meta Agent that uses other Agents (referred to as Inner Agents) as functions\\nCreate your Meta agent using Agent() (Note: No different from usual process of creating Agents - your Meta Agent is also an Agent)\\nSet up an Inner Agent list and assign it to your Meta agent using assign_agents(agent_list)\\nExample Meta Agent Setup\\n# Define your meta-agent\\nmy_agent = Agent(\\'Menu Creator\\', \\'Creates a menu for a restaurant. Menu item includes Name, Description, Ingredients, Pricing.\\')\\n# Define your agent list. Note you can just assign functions to the agent in place using .assign_functions(function_list)\\nagent_list = [\\n Agent(\\'Chef\\', \\'Takes in dish names and comes up with ingredients for each of them. Does not generate prices.\\'),\\n Agent(\\'Boss\\', \\'\\'Does final quality check on menu items\\'),\\n Agent(\\'Creative Writer\\', \\'Takes in a cuisine type and generates interesting dish names and descriptions. Does not generate prices or ingredients.\\', max_subtasks = 2),\\n Agent(\\'Economist\\', \\'Takes in dish names and comes up with fictitious pricing for each of them\\')\\n ]\\nmy_agent.assign_agents(agent_list)\\nRun the Meta Agent\\nLet us run the agent and see the interactions between the Meta Agent and Inner Agents to solve the task!\\noutput = my_agent.run(\\'Give me 5 menu items with name, description, ingredients and price based on Italian food choices. Ensure all parts of menu are generated.\\')\\nShared Variables - See Tutorial 3\\n\"Because text is not enough\" - Anonymous\\nshared_variables is a dictionary, that is initialised in Agent (default empty dictionary), and can be referenced by any function of the agent (including Inner Agents and their functions)\\nThis can be useful for non-text modalitiies (e.g. audio, pdfs, image) and lengthy text modalities, which we do not want to output into subtasks_completed directly\\ns_ at the start of the variable names means shared variables\\nFor input, it means we take the variable from shared_variables instead of LLM generated input\\nFor output, it means we store the variable into shared_variables instead of storing it in subtasks_completed. If subtasks_completed output is empty, it will be output as {\\'Status\\': \\'Completed\\'}\\nExample shared variables names: s_sum, s_total, s_list_of_words\\nExample Input\\n# Function takes in increment (LLM generated) and s_total (retrieves from shared variable dict), and outputs to s_total (in shared variable dict)\\nadd = Function(fn_description = \"Add <increment: int> to <s_total>\", output_format = {\"s_total\": \"Modified total\"})\\n# Define the calculator agent and the shared_variables - Note the naming convention of s_ at the start of the names for shared variables\\nmy_agent = Agent(\\'Calculator\\', \\'Does computations\\', shared_variables = {\\'s_total\\': 0}).assign_functions([add])\\noutput = my_agent.run(\\'Increment total by 1\\')\\nprint(\\'Shared Variables:\\', my_agent.shared_variables)\\nExample Output\\nSubtask identified: Add 1 to the total\\nCalling function add_int_to_variable with parameters {\\'increment\\': 1}\\n{\\'Status\\': \\'Completed\\'}\\nTask completed successfully!\\nShared Variables: {\\'s_total\\': 1}\\nExample External Function Accessing Shared Variables (Advanced)\\n# Use shared_variables as input to your external function to access and modify the shared variables\\ndef generate_quotes(shared_variables, number_of_quotes: int, category: str):\\n \\'\\'\\' Generates number_of_quotes quotes about category \\'\\'\\'\\n # Retrieve from shared variables\\n my_quote_list = shared_variables[\\'quote_list\\']\\n ### Add your function code here ###\\n # Store back to shared variables\\n shared_variables[\\'quote_list\\'] = my_quote_list\\ngenerate_quote_fn = Function(output_format = {}, external_fn = generate_quotes)\\nMemory - See Tutorial 4\\nKey Philosophy\\nIt would be important to learn from past experience and improve the agentic framework - memory is key to that\\nYou can add to the memory bank of your Agents pre-inference (by collecting from a pool of data prior to running the Agent), or during inference (add on in between running subtasks)\\nUse Memory in Agents\\nAgent class takes memory_bank as a parameter during initialisation of an Agent\\nmemory_bank: class Dict[Memory]. Stores multiple types of memory for use by the agent. Customise the Memory config within the Memory class.\\nDefault: memory_bank = {\\'Function\\': Memory(top_k = 5, mapper = lambda x: x.fn_description, approach = \\'retrieve_by_ranker\\')}\\nKey: Function (Already Implemented Natively) - Does RAG over Task -> Function mapping\\nCan add in more keys that would fit your use case. Retrieves similar items to task/overall plan (if able) for additional context in get_next_subtasks() and use_llm() function\\nSide Note: RAG can also be done (and may be preferred) as a separate function of the Agent to retrieve more information when needed (so that we do not overload the Agent with information)\\nMemory Class\\nRetrieves top k memory items based on task\\nInputs:\\nmemory: List. Default: Empty List. The list containing the memory items\\ntop_k: Int. Default: 3. The number of memory list items to retrieve\\nmapper: Function. Maps the memory item to another form for comparison by ranker or LLM. Default: lambda x: x\\nExample mapping: lambda x: x.fn_description (If x is a Class and the string you want to compare for similarity is the fn_description attribute of that class)\\napproach: str. Either retrieve_by_ranker or retrieve_by_llm to retrieve memory items.\\nRanker is faster and cheaper as it compares via embeddings, but are inferior to LLM-based methods for context information\\nranker: Ranker. The Ranker which defines a similarity score between a query and a key. Default: OpenAI text-embedding-3-small model.\\nCan be replaced with a function which returns similarity score from 0 to 1 when given a query and key\\nExample Use Case\\nHelps to reduce number of functions present in LLM context for more accurate generation\\noutput = my_agent.run(\\'Calculate 2**10 * (5 + 1) / 10\\')\\nOriginal Function List: add_numbers, subtract_numbers, add_three_numbers, multiply_numbers, divide_numbers, power_of, GCD_of_two_numbers, modulo_of_numbers, absolute_difference, generate_poem_with_numbers, List_related_words, generate_quote\\nFiltered Function Names: add_three_numbers, multiply_numbers, divide_numbers, power_of, modulo_of_numbers\\nGlobal Context - See Tutorial 5 (Advanced)\\nAgent takes in one additional parameter: get_global_context\\nThis is a function that takes in the agent\\'s internal parameters (self) and outputs a string to the LLM to append to the prompts of any LLM-based calls internally, e.g. get_next_subtask, use_llm, reply_to_user\\nYou have full flexibility to access anything the agent knows and configure a global prompt to the agent\\nUses\\nUsed mainly to provide persistent variables to an agent that is not conveniently stored in subtasks_completed, e.g. ingredients remaining, location in grid for robot\\nImplementing your own specific instructions to the default planner prompt\\nImplement your own memory-based RAG / global prompt instruction if you need more than what the default prompt can achieve\\nAvoid Multiple Similar Subtasks in subtasks_history\\nIf you have multiple similar subtask names, then it is likely the Agent can be confused and think it has already done the subtask\\nIn this case, you can disambiguate by resetting the agent and store the persistent information in shared_variables and provide it to the agent using get_global_context\\nHas the benefit of shifting the Start State closer to End State desired by resetting the Agent\\'s planning cycle\\nKnown Limitations\\nTo be added\\nContributing to the project\\nTest locally\\nClone the repository\\nIf using a virtual environment, activate it\\ncd into taskgen repository\\nInstall the package via command line pip install -e .\\nNow you can import the package and use it in your code\\nSubmitting a pull request\\nFork the repository\\nCreate a new branch\\nMake your changes\\nPush your changes to your fork\\nSubmit a pull request\\nWhat are we looking out for?\\nIntegrations with functions - It would be good if we could import function definitions from elsewhere, e.g. LangChain, into the format shown here. It might even be done automatically using LLM-based conversion using StrictJSON!\\nJupyter Notebooks showcasing what could be done with the framework for something useful. Let your imagination guide you, we look forward to see what you create\\nOther Known Limitations - Do test the framework out extensively and note its failure cases. We will see if we can address them, if not we will put them in Known Limitations.\\n(For the prompt engineer). If you could find a better way to make the prompts work, let us know directly - we do need to test this out across all Tutorial Jupyter Notebooks to make sure that it really works with existing datasets. Also, if you are using other LLMs beside OpenAI, and find the prompts do not work as well - try to rejig your own prompts and let us know as well!\\nAbout\\n Task-based Agentic Framework using StrictJSON as the core\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nCustom properties\\nStars\\n75\\n stars\\nWatchers\\n4\\n watching\\nForks\\n10\\n forks\\n Report repository\\n Releases\\nNo releases published\\n Packages\\n 0\\n No packages published Contributors\\n 3\\nLanguages\\nJupyter Notebook\\n97.0%\\nPython\\n3.0%\\nFooter\\n Â© 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You canâ€™t perform that action at this time.'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The data from the TaskGen website has been successfully scraped. The information includes details about the framework, its features, usage, and examples.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, we need to scrape data from the CrewAI website and then compare the two frameworks based on the information gathered.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Scrape data from the CrewAI website at 'https://github.com/joaomdmoura/CrewAI'.\u001b[0m\n",
      "Calling function scrape_website_tool with parameters {'website_url': 'https://github.com/joaomdmoura/CrewAI'}\n",
      "Using Tool: Read website content\n",
      "> {'output_1': 'GitHub - joaomdmoura/crewAI: Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n joaomdmoura\\n/\\ncrewAI\\nPublic\\nNotifications\\nFork\\n 1.9k\\n Star\\n 14.3k\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nLicense\\n MIT license\\n14.3k\\n stars\\n1.9k\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n292\\nPull requests\\n18\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\njoaomdmoura/crewAI\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History465 Commits.cache/plugin/social.cache/plugin/social\\xa0\\xa0.github/workflows.github/workflows\\xa0\\xa0docsdocs\\xa0\\xa0src/crewaisrc/crewai\\xa0\\xa0teststests\\xa0\\xa0.editorconfig.editorconfig\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0.pre-commit-config.yaml.pre-commit-config.yaml\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0crewAI.excalidrawcrewAI.excalidraw\\xa0\\xa0mkdocs.ymlmkdocs.yml\\xa0\\xa0poetry.lockpoetry.lock\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0View all filesRepository files navigationREADMEMIT license\\ncrewAI\\nðŸ¤– crewAI: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nHomepage | Documentation | Chat with Docs | Examples | Discord\\nTable of contents\\nWhy CrewAI?\\nGetting Started\\nKey Features\\nExamples\\nQuick Tutorial\\nWrite Job Descriptions\\nTrip Planner\\nStock Analysis\\nConnecting Your Crew to a Model\\nHow CrewAI Compares\\nContribution\\nTelemetry\\nLicense\\nWhy CrewAI?\\nThe power of AI collaboration has too much to offer.\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you\\'re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\nGetting Started\\nTo get started with CrewAI, follow these simple steps:\\n1. Installation\\npip install crewai\\nIf you want to install the \\'crewai\\' package along with its optional features that include additional tools for agents, you can do so by using the following command: pip install \\'crewai[tools]\\'. This command installs the basic package and also adds extra components which require more dependencies to function.\"\\npip install \\'crewai[tools]\\'\\n2. Setting Up Your Crew\\nimport os\\nfrom crewai import Agent, Task, Crew, Process\\nfrom crewai_tools import SerperDevTool\\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\n# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.\\n# os.environ[\"OPENAI_API_BASE\"] = \\'http://localhost:11434/v1\\'\\n# os.environ[\"OPENAI_MODEL_NAME\"] =\\'openhermes\\' # Adjust based on available model\\n# os.environ[\"OPENAI_API_KEY\"] =\\'sk-111111111111111111111111111111111111111111111111\\'\\nsearch_tool = SerperDevTool()\\n# Define your agents with roles and goals\\nresearcher = Agent(\\n role=\\'Senior Research Analyst\\',\\n goal=\\'Uncover cutting-edge developments in AI and data science\\',\\n backstory=\"\"\"You work at a leading tech think tank.\\n Your expertise lies in identifying emerging trends.\\n You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\\n verbose=True,\\n allow_delegation=False,\\n tools=[search_tool]\\n # You can pass an optional llm attribute specifying what model you wanna use.\\n # It can be a local model through Ollama / LM Studio or a remote\\n # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\\n #\\n # import os\\n # os.environ[\\'OPENAI_MODEL_NAME\\'] = \\'gpt-3.5-turbo\\'\\n #\\n # OR\\n #\\n # from langchain_openai import ChatOpenAI\\n # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\\n)\\nwriter = Agent(\\n role=\\'Tech Content Strategist\\',\\n goal=\\'Craft compelling content on tech advancements\\',\\n backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\\n You transform complex concepts into compelling narratives.\"\"\",\\n verbose=True,\\n allow_delegation=True\\n)\\n# Create tasks for your agents\\ntask1 = Task(\\n description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\\n Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\\n expected_output=\"Full analysis report in bullet points\",\\n agent=researcher\\n)\\ntask2 = Task(\\n description=\"\"\"Using the insights provided, develop an engaging blog\\n post that highlights the most significant AI advancements.\\n Your post should be informative yet accessible, catering to a tech-savvy audience.\\n Make it sound cool, avoid complex words so it doesn\\'t sound like AI.\"\"\",\\n expected_output=\"Full blog post of at least 4 paragraphs\",\\n agent=writer\\n)\\n# Instantiate your crew with a sequential process\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[task1, task2],\\n verbose=2, # You can set it to 1 or 2 to different logging levels\\n)\\n# Get your crew to work!\\nresult = crew.kickoff()\\nprint(\"######################\")\\nprint(result)\\nIn addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. See more about the processes here.\\nKey Features\\nRole-Based Agent Design: Customize agents with specific roles, goals, and tools.\\nAutonomous Inter-Agent Delegation: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.\\nFlexible Task Management: Define tasks with customizable tools and assign them to agents dynamically.\\nProcesses Driven: Currently only supports sequential task execution and hierarchical processes, but more complex processes like consensual and autonomous are being worked on.\\nSave output as file: Save the output of individual tasks as a file, so you can use it later.\\nParse output as Pydantic or Json: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.\\nWorks with Open Source Models: Run your crew using Open AI or open source models refer to the Connect crewAI to LLMs page for details on configuring your agents\\' connections to models, even ones running locally!\\nExamples\\nYou can test different real life examples of AI crews in the crewAI-examples repo:\\nLanding Page Generator\\nHaving Human input on the execution\\nTrip Planner\\nStock Analysis\\nQuick Tutorial\\nWrite Job Descriptions\\nCheck out code for this example or watch a video below:\\nTrip Planner\\nCheck out code for this example or watch a video below:\\nStock Analysis\\nCheck out code for this example or watch a video below:\\nConnecting Your Crew to a Model\\ncrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.\\nPlease refer to the Connect crewAI to LLMs page for details on configuring you agents\\' connections to models.\\nHow CrewAI Compares\\nAutogen: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents\\' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.\\nChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.\\nCrewAI\\'s Advantage: CrewAI is built with production in mind. It offers the flexibility of Autogen\\'s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI\\'s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.\\nContribution\\nCrewAI is open-source and we welcome contributions. If you\\'re looking to contribute, please:\\nFork the repository.\\nCreate a new branch for your feature.\\nAdd your feature or improvement.\\nSend a pull request.\\nWe appreciate your input!\\nInstalling Dependencies\\npoetry lock\\npoetry install\\nVirtual Env\\npoetry shell\\nPre-commit hooks\\npre-commit install\\nRunning Tests\\npoetry run pytest\\nRunning static type checks\\npoetry run mypy\\nPackaging\\npoetry build\\nInstalling Locally\\npip install dist/*.tar.gz\\nTelemetry\\nCrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.\\nThere is NO data being collected on the prompts, tasks descriptions agents backstories or goals nor tools usage, no API calls, nor responses nor any data that is being processed by the agents, nor any secrets and env vars.\\nData collected includes:\\nVersion of crewAI\\nSo we can understand how many users are using the latest version\\nVersion of Python\\nSo we can decide on what versions to better support\\nGeneral OS (e.g. number of CPUs, macOS/Windows/Linux)\\nSo we know what OS we should focus on and if we could build specific OS related features\\nNumber of agents and tasks in a crew\\nSo we make sure we are testing internally with similar use cases and educate people on the best practices\\nCrew Process being used\\nUnderstand where we should focus our efforts\\nIf Agents are using memory or allowing delegation\\nUnderstand if we improved the features or maybe even drop them\\nIf Tasks are being executed in parallel or sequentially\\nUnderstand if we should focus more on parallel execution\\nLanguage model being used\\nImproved support on most used languages\\nRoles of agents in a crew\\nUnderstand high level use cases so we can build better tools, integrations and examples about it\\nTools names available\\nUnderstand out of the publically available tools, which ones are being used the most so we can improve them\\nUsers can opt-in sharing the complete telemetry data by setting the share_crew attribute to True on their Crews.\\nLicense\\nCrewAI is released under the MIT License.\\nAbout\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nTopics\\n ai\\n agents\\n ai-agents\\n llms\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nStars\\n14.3k\\n stars\\nWatchers\\n171\\n watching\\nForks\\n1.9k\\n forks\\n Report repository\\n Releases\\n 35\\nv0.30.8\\n Latest\\nMay 14, 2024\\n + 34 releases\\n Packages\\n 0\\n No packages published Used by 982\\n + 974\\n Contributors\\n 75\\n + 61 contributors\\nLanguages\\nPython\\n100.0%\\nFooter\\n Â© 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You canâ€™t perform that action at this time.'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The data from both the TaskGen and CrewAI websites has been successfully scraped. TaskGen is a task-based agentic framework using StrictJSON as the core, while CrewAI is a framework for orchestrating role-playing, autonomous AI agents to foster collaborative intelligence.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, we need to summarize the key differences between TaskGen and CrewAI based on the scraped data. This can be done using the LLM to generate a concise comparison.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Summarize the key differences between TaskGen and CrewAI based on the scraped data.\u001b[0m\n",
      "Getting LLM to perform the following task: Summarize the key differences between TaskGen and CrewAI based on the scraped data.\n",
      "> TaskGen and CrewAI are both frameworks designed to facilitate the use of AI agents, but they have distinct differences in their approach and features.\n",
      "\n",
      "1. **Core Philosophy and Design**:\n",
      "   - **TaskGen**: Focuses on a task-based agentic framework using StrictJSON as the core. It emphasizes breaking down tasks into subtasks and using JSON for efficient task execution and Chain of Thought prompting.\n",
      "   - **CrewAI**: Aims to orchestrate role-playing, autonomous AI agents to foster collaborative intelligence. It emphasizes agents working together seamlessly to tackle complex tasks, with a focus on role-based agent design and inter-agent delegation.\n",
      "\n",
      "2. **Key Features**:\n",
      "   - **TaskGen**:\n",
      "     - Uses StrictJSON for task execution.\n",
      "     - Supports single agents with LLM functions, external functions, and meta agents with inner agents.\n",
      "     - Features shared variables for multi-modality support, memory for task-based prompts, and global context configuration.\n",
      "     - Emphasizes JSON messaging for natural parsing and less verbosity.\n",
      "   - **CrewAI**:\n",
      "     - Role-based agent design with customizable roles, goals, and tools.\n",
      "     - Autonomous inter-agent delegation and flexible task management.\n",
      "     - Supports sequential and hierarchical processes, with more complex processes in development.\n",
      "     - Allows saving output as files and parsing output as Pydantic models or JSON.\n",
      "     - Works with both OpenAI and open-source models.\n",
      "\n",
      "3. **Installation and Setup**:\n",
      "   - **TaskGen**: Installation via `pip install taskgen-ai`. Requires setting up an OpenAPI API key and importing functions from TaskGen.\n",
      "   - **CrewAI**: Installation via `pip install crewai` or `pip install 'crewai[tools]'` for additional tools. Requires setting up API keys for OpenAI and other tools, and defining agents, tasks, and processes.\n",
      "\n",
      "4. **Example Use Cases**:\n",
      "   - **TaskGen**: Example tasks include generating rhyming words and composing poems, with a focus on efficient task execution and JSON-based outputs.\n",
      "   - **CrewAI**: Examples include trip planning, stock analysis, and content creation, with a focus on collaborative agent interactions and role-based task execution.\n",
      "\n",
      "5. **Community and Contribution**:\n",
      "   - **TaskGen**: Encourages contributions of external function integrations and Jupyter Notebooks for various use cases. Provides detailed tutorials and community support via Discord.\n",
      "   - **CrewAI**: Open-source with a welcoming approach to contributions. Provides detailed documentation, examples, and a Discord community for support.\n",
      "\n",
      "6. **Telemetry and Data Collection**:\n",
      "   - **TaskGen**: No specific mention of telemetry or data collection.\n",
      "   - **CrewAI**: Uses anonymous telemetry to collect usage data to improve the library. Data collected includes version information, OS details, number of agents and tasks, and language models used. Users can opt-in for complete telemetry data sharing.\n",
      "\n",
      "In summary, TaskGen is more focused on task-based execution using JSON, while CrewAI emphasizes collaborative intelligence and role-based agent interactions. TaskGen is designed for efficient task execution with JSON, whereas CrewAI provides a flexible framework for orchestrating multiple agents with specific roles and goals.\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The key differences between TaskGen and CrewAI have been summarized based on the scraped data from their respective GitHub pages.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The assigned task of identifying the differences between TaskGen and CrewAI has been completed. The summary provided includes core philosophy, key features, installation and setup, example use cases, community and contribution, and telemetry and data collection.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n simbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n 10\\n Star\\n 75\\n Task-based Agentic Framework using StrictJSON as the core\\nLicense\\n MIT license\\n75\\n stars\\n10\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History92 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_07May2024.ipynbTaskGen AMA_07May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.1.1\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion\\nfn_name - String. If provided, this will be the name of the function. Ohterwise, if external_fn is provided, it will be the name of external_fn. Otherwise, we will use LLM to generate a function name from the fn_description\\nkwargs - Dict. Additional arguments you would like to pass on to the strict_json function\\nOutputs:\\nJSON of output variables in a dictionary (similar to strict_json)\\nExample Internal LLM-Based Function\\n# Construct the function: var1 will be first input variable, var2 will be second input variable and so on\\nsentence_style = Function(fn_description = \\'Output a sentence with words <var1> and <var2> in the style of <var3>\\', output_format = {\\'output\\': \\'sentence\\'})\\n# Use the function\\nsentence_style(\\'ball\\', \\'dog\\', \\'happy\\') #var1, var2, var3\\nExample Output\\n{\\'output\\': \\'The happy dog chased the ball.\\'}\\nExample External Function\\ndef binary_to_decimal(x):\\n return int(str(x), 2)\\n# an external function with a single output variable, with an expressive variable description\\nb2d = Function(fn_description = \\'Convert input <x: a binary number in base 2> to base 10\\', output_format = {\\'output1\\': \\'x in base 10\\'},\\n external_fn = binary_to_decimal)\\n# Use the function\\nb2d(10) #x\\nExample Output\\n{\\'output1\\': 2}\\nExample fn_description inferred from type hints and docstring of External Function\\n# Docstring must provide all input variables\\n# We will ignore shared_variables, *args and **kwargs\\nfrom typing import List\\ndef add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\\n \\'\\'\\'Adds num1 to num_list\\'\\'\\'\\n num_list.append(num1)\\n return num_list\\nfn = Function(external_fn = add_number_to_list, #output_format = {\\'num_array\\': \\'Array of numbers\\'} ## If you would like to name output variables (helps with LLM understanding), define your own output_format\\n )\\nstr(fn)\\nExample Output\\nDescription: Adds Adds <num1: int> to <num_list: list[int]>\\nInput: [\\'num1\\', \\'num_list\\']\\nOutput: {\\'output_1\\': \\'list[int]\\'}\\nPower Up your Agents - Bring in Functions (aka Tools)\\nAfter creating your agent, use assign_functions to assign a list of functions (of class Function) to it\\nFunction names will be automatically inferred if not specified\\nProceed to run tasks by using run()\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nmy_agent.assign_functions([sentence_style, b2d])\\noutput = my_agent.run(\\'Generate me a happy sentence with a number and a ball. The number is 1001 converted to decimal\\')\\nSubtask identified: Convert the binary number 1001 to decimal\\nCalling function binary_to_decimal with parameters {\\'x\\': \\'1001\\'}\\n{\\'output1\\': 9}\\nSubtask identified: Generate a happy sentence with the decimal number and a ball\\nCalling function sentence_with_objects_entities_emotion with parameters {\\'obj\\': \\'9\\', \\'entity\\': \\'ball\\', \\'emotion\\': \\'happy\\'}\\n{\\'output\\': \\'I am so happy with my 9 balls.\\'}\\nTask completed successfully!\\nSaving and Loading Agents\\nSometimes you want to configure your agents and save them and load them elsewhere, while maintaining the current agent state\\nWhen you use the save_agent function, we store the entire agent\\'s internal state, include name, description, list of functions, subtasks history and all other internal variables into a pickle file\\nWhen you use the load_agent function, and we will load the entire agent saved in the pickle file into the existing agent\\nKey functions:\\nsave_agent(pickle_file_name: str): Saves the agent\\'s internal parameters to a pickle file named pickle_file_name (include .pkl), returns the pickle file\\nload_agent(pickle_file_name: str): Loads the agent\\'s internal parameters from a pickle file named pickle_file_name (include .pkl), returns loaded agent\\nExample 1: Saving Agent\\nmy_agent.save_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent saved to myagent.pkl\\nExample 2: Loading Agent\\nnew_agent = Agent().load_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent loaded from myagent.pkl\\nInception: Agents within Agents - See Tutorial 2\\nYou can also create a Meta Agent that uses other Agents (referred to as Inner Agents) as functions\\nCreate your Meta agent using Agent() (Note: No different from usual process of creating Agents - your Meta Agent is also an Agent)\\nSet up an Inner Agent list and assign it to your Meta agent using assign_agents(agent_list)\\nExample Meta Agent Setup\\n# Define your meta-agent\\nmy_agent = Agent(\\'Menu Creator\\', \\'Creates a menu for a restaurant. Menu item includes Name, Description, Ingredients, Pricing.\\')\\n# Define your agent list. Note you can just assign functions to the agent in place using .assign_functions(function_list)\\nagent_list = [\\n Agent(\\'Chef\\', \\'Takes in dish names and comes up with ingredients for each of them. Does not generate prices.\\'),\\n Agent(\\'Boss\\', \\'\\'Does final quality check on menu items\\'),\\n Agent(\\'Creative Writer\\', \\'Takes in a cuisine type and generates interesting dish names and descriptions. Does not generate prices or ingredients.\\', max_subtasks = 2),\\n Agent(\\'Economist\\', \\'Takes in dish names and comes up with fictitious pricing for each of them\\')\\n ]\\nmy_agent.assign_agents(agent_list)\\nRun the Meta Agent\\nLet us run the agent and see the interactions between the Meta Agent and Inner Agents to solve the task!\\noutput = my_agent.run(\\'Give me 5 menu items with name, description, ingredients and price based on Italian food choices. Ensure all parts of menu are generated.\\')\\nShared Variables - See Tutorial 3\\n\"Because text is not enough\" - Anonymous\\nshared_variables is a dictionary, that is initialised in Agent (default empty dictionary), and can be referenced by any function of the agent (including Inner Agents and their functions)\\nThis can be useful for non-text modalitiies (e.g. audio, pdfs, image) and lengthy text modalities, which we do not want to output into subtasks_completed directly\\ns_ at the start of the variable names means shared variables\\nFor input, it means we take the variable from shared_variables instead of LLM generated input\\nFor output, it means we store the variable into shared_variables instead of storing it in subtasks_completed. If subtasks_completed output is empty, it will be output as {\\'Status\\': \\'Completed\\'}\\nExample shared variables names: s_sum, s_total, s_list_of_words\\nExample Input\\n# Function takes in increment (LLM generated) and s_total (retrieves from shared variable dict), and outputs to s_total (in shared variable dict)\\nadd = Function(fn_description = \"Add <increment: int> to <s_total>\", output_format = {\"s_total\": \"Modified total\"})\\n# Define the calculator agent and the shared_variables - Note the naming convention of s_ at the start of the names for shared variables\\nmy_agent = Agent(\\'Calculator\\', \\'Does computations\\', shared_variables = {\\'s_total\\': 0}).assign_functions([add])\\noutput = my_agent.run(\\'Increment total by 1\\')\\nprint(\\'Shared Variables:\\', my_agent.shared_variables)\\nExample Output\\nSubtask identified: Add 1 to the total\\nCalling function add_int_to_variable with parameters {\\'increment\\': 1}\\n{\\'Status\\': \\'Completed\\'}\\nTask completed successfully!\\nShared Variables: {\\'s_total\\': 1}\\nExample External Function Accessing Shared Variables (Advanced)\\n# Use shared_variables as input to your external function to access and modify the shared variables\\ndef generate_quotes(shared_variables, number_of_quotes: int, category: str):\\n \\'\\'\\' Generates number_of_quotes quotes about category \\'\\'\\'\\n # Retrieve from shared variables\\n my_quote_list = shared_variables[\\'quote_list\\']\\n ### Add your function code here ###\\n # Store back to shared variables\\n shared_variables[\\'quote_list\\'] = my_quote_list\\ngenerate_quote_fn = Function(output_format = {}, external_fn = generate_quotes)\\nMemory - See Tutorial 4\\nKey Philosophy\\nIt would be important to learn from past experience and improve the agentic framework - memory is key to that\\nYou can add to the memory bank of your Agents pre-inference (by collecting from a pool of data prior to running the Agent), or during inference (add on in between running subtasks)\\nUse Memory in Agents\\nAgent class takes memory_bank as a parameter during initialisation of an Agent\\nmemory_bank: class Dict[Memory]. Stores multiple types of memory for use by the agent. Customise the Memory config within the Memory class.\\nDefault: memory_bank = {\\'Function\\': Memory(top_k = 5, mapper = lambda x: x.fn_description, approach = \\'retrieve_by_ranker\\')}\\nKey: Function (Already Implemented Natively) - Does RAG over Task -> Function mapping\\nCan add in more keys that would fit your use case. Retrieves similar items to task/overall plan (if able) for additional context in get_next_subtasks() and use_llm() function\\nSide Note: RAG can also be done (and may be preferred) as a separate function of the Agent to retrieve more information when needed (so that we do not overload the Agent with information)\\nMemory Class\\nRetrieves top k memory items based on task\\nInputs:\\nmemory: List. Default: Empty List. The list containing the memory items\\ntop_k: Int. Default: 3. The number of memory list items to retrieve\\nmapper: Function. Maps the memory item to another form for comparison by ranker or LLM. Default: lambda x: x\\nExample mapping: lambda x: x.fn_description (If x is a Class and the string you want to compare for similarity is the fn_description attribute of that class)\\napproach: str. Either retrieve_by_ranker or retrieve_by_llm to retrieve memory items.\\nRanker is faster and cheaper as it compares via embeddings, but are inferior to LLM-based methods for context information\\nranker: Ranker. The Ranker which defines a similarity score between a query and a key. Default: OpenAI text-embedding-3-small model.\\nCan be replaced with a function which returns similarity score from 0 to 1 when given a query and key\\nExample Use Case\\nHelps to reduce number of functions present in LLM context for more accurate generation\\noutput = my_agent.run(\\'Calculate 2**10 * (5 + 1) / 10\\')\\nOriginal Function List: add_numbers, subtract_numbers, add_three_numbers, multiply_numbers, divide_numbers, power_of, GCD_of_two_numbers, modulo_of_numbers, absolute_difference, generate_poem_with_numbers, List_related_words, generate_quote\\nFiltered Function Names: add_three_numbers, multiply_numbers, divide_numbers, power_of, modulo_of_numbers\\nGlobal Context - See Tutorial 5 (Advanced)\\nAgent takes in one additional parameter: get_global_context\\nThis is a function that takes in the agent\\'s internal parameters (self) and outputs a string to the LLM to append to the prompts of any LLM-based calls internally, e.g. get_next_subtask, use_llm, reply_to_user\\nYou have full flexibility to access anything the agent knows and configure a global prompt to the agent\\nUses\\nUsed mainly to provide persistent variables to an agent that is not conveniently stored in subtasks_completed, e.g. ingredients remaining, location in grid for robot\\nImplementing your own specific instructions to the default planner prompt\\nImplement your own memory-based RAG / global prompt instruction if you need more than what the default prompt can achieve\\nAvoid Multiple Similar Subtasks in subtasks_history\\nIf you have multiple similar subtask names, then it is likely the Agent can be confused and think it has already done the subtask\\nIn this case, you can disambiguate by resetting the agent and store the persistent information in shared_variables and provide it to the agent using get_global_context\\nHas the benefit of shifting the Start State closer to End State desired by resetting the Agent\\'s planning cycle\\nKnown Limitations\\nTo be added\\nContributing to the project\\nTest locally\\nClone the repository\\nIf using a virtual environment, activate it\\ncd into taskgen repository\\nInstall the package via command line pip install -e .\\nNow you can import the package and use it in your code\\nSubmitting a pull request\\nFork the repository\\nCreate a new branch\\nMake your changes\\nPush your changes to your fork\\nSubmit a pull request\\nWhat are we looking out for?\\nIntegrations with functions - It would be good if we could import function definitions from elsewhere, e.g. LangChain, into the format shown here. It might even be done automatically using LLM-based conversion using StrictJSON!\\nJupyter Notebooks showcasing what could be done with the framework for something useful. Let your imagination guide you, we look forward to see what you create\\nOther Known Limitations - Do test the framework out extensively and note its failure cases. We will see if we can address them, if not we will put them in Known Limitations.\\n(For the prompt engineer). If you could find a better way to make the prompts work, let us know directly - we do need to test this out across all Tutorial Jupyter Notebooks to make sure that it really works with existing datasets. Also, if you are using other LLMs beside OpenAI, and find the prompts do not work as well - try to rejig your own prompts and let us know as well!\\nAbout\\n Task-based Agentic Framework using StrictJSON as the core\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nCustom properties\\nStars\\n75\\n stars\\nWatchers\\n4\\n watching\\nForks\\n10\\n forks\\n Report repository\\n Releases\\nNo releases published\\n Packages\\n 0\\n No packages published Contributors\\n 3\\nLanguages\\nJupyter Notebook\\n97.0%\\nPython\\n3.0%\\nFooter\\n Â© 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You canâ€™t perform that action at this time.'},\n",
       " {'output_1': 'GitHub - joaomdmoura/crewAI: Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n joaomdmoura\\n/\\ncrewAI\\nPublic\\nNotifications\\nFork\\n 1.9k\\n Star\\n 14.3k\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nLicense\\n MIT license\\n14.3k\\n stars\\n1.9k\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n292\\nPull requests\\n18\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\njoaomdmoura/crewAI\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History465 Commits.cache/plugin/social.cache/plugin/social\\xa0\\xa0.github/workflows.github/workflows\\xa0\\xa0docsdocs\\xa0\\xa0src/crewaisrc/crewai\\xa0\\xa0teststests\\xa0\\xa0.editorconfig.editorconfig\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0.pre-commit-config.yaml.pre-commit-config.yaml\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0crewAI.excalidrawcrewAI.excalidraw\\xa0\\xa0mkdocs.ymlmkdocs.yml\\xa0\\xa0poetry.lockpoetry.lock\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0View all filesRepository files navigationREADMEMIT license\\ncrewAI\\nðŸ¤– crewAI: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nHomepage | Documentation | Chat with Docs | Examples | Discord\\nTable of contents\\nWhy CrewAI?\\nGetting Started\\nKey Features\\nExamples\\nQuick Tutorial\\nWrite Job Descriptions\\nTrip Planner\\nStock Analysis\\nConnecting Your Crew to a Model\\nHow CrewAI Compares\\nContribution\\nTelemetry\\nLicense\\nWhy CrewAI?\\nThe power of AI collaboration has too much to offer.\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you\\'re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\nGetting Started\\nTo get started with CrewAI, follow these simple steps:\\n1. Installation\\npip install crewai\\nIf you want to install the \\'crewai\\' package along with its optional features that include additional tools for agents, you can do so by using the following command: pip install \\'crewai[tools]\\'. This command installs the basic package and also adds extra components which require more dependencies to function.\"\\npip install \\'crewai[tools]\\'\\n2. Setting Up Your Crew\\nimport os\\nfrom crewai import Agent, Task, Crew, Process\\nfrom crewai_tools import SerperDevTool\\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\n# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.\\n# os.environ[\"OPENAI_API_BASE\"] = \\'http://localhost:11434/v1\\'\\n# os.environ[\"OPENAI_MODEL_NAME\"] =\\'openhermes\\' # Adjust based on available model\\n# os.environ[\"OPENAI_API_KEY\"] =\\'sk-111111111111111111111111111111111111111111111111\\'\\nsearch_tool = SerperDevTool()\\n# Define your agents with roles and goals\\nresearcher = Agent(\\n role=\\'Senior Research Analyst\\',\\n goal=\\'Uncover cutting-edge developments in AI and data science\\',\\n backstory=\"\"\"You work at a leading tech think tank.\\n Your expertise lies in identifying emerging trends.\\n You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\\n verbose=True,\\n allow_delegation=False,\\n tools=[search_tool]\\n # You can pass an optional llm attribute specifying what model you wanna use.\\n # It can be a local model through Ollama / LM Studio or a remote\\n # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\\n #\\n # import os\\n # os.environ[\\'OPENAI_MODEL_NAME\\'] = \\'gpt-3.5-turbo\\'\\n #\\n # OR\\n #\\n # from langchain_openai import ChatOpenAI\\n # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\\n)\\nwriter = Agent(\\n role=\\'Tech Content Strategist\\',\\n goal=\\'Craft compelling content on tech advancements\\',\\n backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\\n You transform complex concepts into compelling narratives.\"\"\",\\n verbose=True,\\n allow_delegation=True\\n)\\n# Create tasks for your agents\\ntask1 = Task(\\n description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\\n Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\\n expected_output=\"Full analysis report in bullet points\",\\n agent=researcher\\n)\\ntask2 = Task(\\n description=\"\"\"Using the insights provided, develop an engaging blog\\n post that highlights the most significant AI advancements.\\n Your post should be informative yet accessible, catering to a tech-savvy audience.\\n Make it sound cool, avoid complex words so it doesn\\'t sound like AI.\"\"\",\\n expected_output=\"Full blog post of at least 4 paragraphs\",\\n agent=writer\\n)\\n# Instantiate your crew with a sequential process\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[task1, task2],\\n verbose=2, # You can set it to 1 or 2 to different logging levels\\n)\\n# Get your crew to work!\\nresult = crew.kickoff()\\nprint(\"######################\")\\nprint(result)\\nIn addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. See more about the processes here.\\nKey Features\\nRole-Based Agent Design: Customize agents with specific roles, goals, and tools.\\nAutonomous Inter-Agent Delegation: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.\\nFlexible Task Management: Define tasks with customizable tools and assign them to agents dynamically.\\nProcesses Driven: Currently only supports sequential task execution and hierarchical processes, but more complex processes like consensual and autonomous are being worked on.\\nSave output as file: Save the output of individual tasks as a file, so you can use it later.\\nParse output as Pydantic or Json: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.\\nWorks with Open Source Models: Run your crew using Open AI or open source models refer to the Connect crewAI to LLMs page for details on configuring your agents\\' connections to models, even ones running locally!\\nExamples\\nYou can test different real life examples of AI crews in the crewAI-examples repo:\\nLanding Page Generator\\nHaving Human input on the execution\\nTrip Planner\\nStock Analysis\\nQuick Tutorial\\nWrite Job Descriptions\\nCheck out code for this example or watch a video below:\\nTrip Planner\\nCheck out code for this example or watch a video below:\\nStock Analysis\\nCheck out code for this example or watch a video below:\\nConnecting Your Crew to a Model\\ncrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.\\nPlease refer to the Connect crewAI to LLMs page for details on configuring you agents\\' connections to models.\\nHow CrewAI Compares\\nAutogen: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents\\' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.\\nChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.\\nCrewAI\\'s Advantage: CrewAI is built with production in mind. It offers the flexibility of Autogen\\'s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI\\'s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.\\nContribution\\nCrewAI is open-source and we welcome contributions. If you\\'re looking to contribute, please:\\nFork the repository.\\nCreate a new branch for your feature.\\nAdd your feature or improvement.\\nSend a pull request.\\nWe appreciate your input!\\nInstalling Dependencies\\npoetry lock\\npoetry install\\nVirtual Env\\npoetry shell\\nPre-commit hooks\\npre-commit install\\nRunning Tests\\npoetry run pytest\\nRunning static type checks\\npoetry run mypy\\nPackaging\\npoetry build\\nInstalling Locally\\npip install dist/*.tar.gz\\nTelemetry\\nCrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.\\nThere is NO data being collected on the prompts, tasks descriptions agents backstories or goals nor tools usage, no API calls, nor responses nor any data that is being processed by the agents, nor any secrets and env vars.\\nData collected includes:\\nVersion of crewAI\\nSo we can understand how many users are using the latest version\\nVersion of Python\\nSo we can decide on what versions to better support\\nGeneral OS (e.g. number of CPUs, macOS/Windows/Linux)\\nSo we know what OS we should focus on and if we could build specific OS related features\\nNumber of agents and tasks in a crew\\nSo we make sure we are testing internally with similar use cases and educate people on the best practices\\nCrew Process being used\\nUnderstand where we should focus our efforts\\nIf Agents are using memory or allowing delegation\\nUnderstand if we improved the features or maybe even drop them\\nIf Tasks are being executed in parallel or sequentially\\nUnderstand if we should focus more on parallel execution\\nLanguage model being used\\nImproved support on most used languages\\nRoles of agents in a crew\\nUnderstand high level use cases so we can build better tools, integrations and examples about it\\nTools names available\\nUnderstand out of the publically available tools, which ones are being used the most so we can improve them\\nUsers can opt-in sharing the complete telemetry data by setting the share_crew attribute to True on their Crews.\\nLicense\\nCrewAI is released under the MIT License.\\nAbout\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nTopics\\n ai\\n agents\\n ai-agents\\n llms\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nStars\\n14.3k\\n stars\\nWatchers\\n171\\n watching\\nForks\\n1.9k\\n forks\\n Report repository\\n Releases\\n 35\\nv0.30.8\\n Latest\\nMay 14, 2024\\n + 34 releases\\n Packages\\n 0\\n No packages published Used by 982\\n + 974\\n Contributors\\n 75\\n + 61 contributors\\nLanguages\\nPython\\n100.0%\\nFooter\\n Â© 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You canâ€™t perform that action at this time.'},\n",
       " {'Output': \"TaskGen and CrewAI are both frameworks designed to facilitate the use of AI agents, but they have distinct differences in their approach and features.\\n\\n1. **Core Philosophy and Design**:\\n   - **TaskGen**: Focuses on a task-based agentic framework using StrictJSON as the core. It emphasizes breaking down tasks into subtasks and using JSON for efficient task execution and Chain of Thought prompting.\\n   - **CrewAI**: Aims to orchestrate role-playing, autonomous AI agents to foster collaborative intelligence. It emphasizes agents working together seamlessly to tackle complex tasks, with a focus on role-based agent design and inter-agent delegation.\\n\\n2. **Key Features**:\\n   - **TaskGen**:\\n     - Uses StrictJSON for task execution.\\n     - Supports single agents with LLM functions, external functions, and meta agents with inner agents.\\n     - Features shared variables for multi-modality support, memory for task-based prompts, and global context configuration.\\n     - Emphasizes JSON messaging for natural parsing and less verbosity.\\n   - **CrewAI**:\\n     - Role-based agent design with customizable roles, goals, and tools.\\n     - Autonomous inter-agent delegation and flexible task management.\\n     - Supports sequential and hierarchical processes, with more complex processes in development.\\n     - Allows saving output as files and parsing output as Pydantic models or JSON.\\n     - Works with both OpenAI and open-source models.\\n\\n3. **Installation and Setup**:\\n   - **TaskGen**: Installation via `pip install taskgen-ai`. Requires setting up an OpenAPI API key and importing functions from TaskGen.\\n   - **CrewAI**: Installation via `pip install crewai` or `pip install 'crewai[tools]'` for additional tools. Requires setting up API keys for OpenAI and other tools, and defining agents, tasks, and processes.\\n\\n4. **Example Use Cases**:\\n   - **TaskGen**: Example tasks include generating rhyming words and composing poems, with a focus on efficient task execution and JSON-based outputs.\\n   - **CrewAI**: Examples include trip planning, stock analysis, and content creation, with a focus on collaborative agent interactions and role-based task execution.\\n\\n5. **Community and Contribution**:\\n   - **TaskGen**: Encourages contributions of external function integrations and Jupyter Notebooks for various use cases. Provides detailed tutorials and community support via Discord.\\n   - **CrewAI**: Open-source with a welcoming approach to contributions. Provides detailed documentation, examples, and a Discord community for support.\\n\\n6. **Telemetry and Data Collection**:\\n   - **TaskGen**: No specific mention of telemetry or data collection.\\n   - **CrewAI**: Uses anonymous telemetry to collect usage data to improve the library. Data collected includes version information, OS details, number of agents and tasks, and language models used. Users can opt-in for complete telemetry data sharing.\\n\\nIn summary, TaskGen is more focused on task-based execution using JSON, while CrewAI emphasizes collaborative intelligence and role-based agent interactions. TaskGen is designed for efficient task execution with JSON, whereas CrewAI provides a flexible framework for orchestrating multiple agents with specific roles and goals.\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What are the differences between TaskGen (\"https://github.com/simbianai/taskgen\") and CrewAI (\"https://github.com/joaomdmoura/CrewAI\")?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910d658e-89e4-4530-972d-e4a37f9f2437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key imports needed for TaskGen and CrewAI based on the scraped data are as follows:\\n\\n1. **TaskGen**:\\n   - To install TaskGen, use the command: `pip install taskgen-ai`.\\n   - Import the required functions from TaskGen in your code. Specific imports are not detailed in the scraped data, but typically you would import the main classes and functions provided by the TaskGen package.\\n\\n2. **CrewAI**:\\n   - To install CrewAI, use the command: `pip install crewai`. For additional tools, use: `pip install 'crewai[tools]'`.\\n   - Key imports for setting up CrewAI include:\\n     ```python\\n     import os\\n     from crewai import Agent, Task, Crew, Process\\n     from crewai_tools import SerperDevTool\\n     ```\\n   - These imports are used to define agents, tasks, and processes, and to set up the necessary environment variables for API keys.\\n\\nIn summary, for TaskGen, you need to install the package and import the necessary functions from TaskGen. For CrewAI, you need to install the package, optionally with additional tools, and import the main classes and tools from the `crewai` and `crewai_tools` modules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The key imports needed for TaskGen and CrewAI based on the scraped data are as follows:\\\\n\\\\n1. **TaskGen**:\\\\n   - To install TaskGen, use the command: `pip install taskgen-ai`.\\\\n   - Import the required functions from TaskGen in your code. Specific imports are not detailed in the scraped data, but typically you would import the main classes and functions provided by the TaskGen package.\\\\n\\\\n2. **CrewAI**:\\\\n   - To install CrewAI, use the command: `pip install crewai`. For additional tools, use: `pip install 'crewai[tools]'`.\\\\n   - Key imports for setting up CrewAI include:\\\\n     ```python\\\\n     import os\\\\n     from crewai import Agent, Task, Crew, Process\\\\n     from crewai_tools import SerperDevTool\\\\n     ```\\\\n   - These imports are used to define agents, tasks, and processes, and to set up the necessary environment variables for API keys.\\\\n\\\\nIn summary, for TaskGen, you need to install the package and import the necessary functions from TaskGen. For CrewAI, you need to install the package, optionally with additional tools, and import the main classes and tools from the `crewai` and `crewai_tools` modules.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What are the key imports needed?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8fbd4a-ab85-4e03-88cd-6e17924e8fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the scraped data, the compatibility of TaskGen and CrewAI with package versions is as follows:\\n\\n1. **TaskGen**:\\n   - The specific versions of packages that TaskGen is compatible with are not detailed in the scraped data. However, it is mentioned that TaskGen is compatible with ChatGPT (gpt-3.5-turbo) and more advanced models like gpt-4-turbo. For robust use, it is recommended to use gpt-4-turbo and better models.\\n   - Installation is done via the command: `pip install taskgen-ai`.\\n   - The repository includes a `requirements.txt` file, which typically lists the dependencies and their versions, but the exact contents of this file are not provided in the scraped data.\\n\\n2. **CrewAI**:\\n   - The specific versions of packages that CrewAI is compatible with are also not detailed in the scraped data. However, it is mentioned that CrewAI works with both OpenAI and open-source models.\\n   - Installation is done via the command: `pip install crewai`. For additional tools, use: `pip install 'crewai[tools]'`.\\n   - The repository includes a `pyproject.toml` file, which typically lists the dependencies and their versions, but the exact contents of this file are not provided in the scraped data.\\n   - CrewAI uses `poetry` for dependency management, and the commands `poetry lock`, `poetry install`, and `poetry shell` are used for setting up the environment.\\n\\nIn summary, while the exact versions of compatible packages are not explicitly mentioned, both TaskGen and CrewAI provide installation commands and include files (`requirements.txt` for TaskGen and `pyproject.toml` for CrewAI) that specify their dependencies. Users should refer to these files in the respective repositories for detailed version information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the scraped data, the compatibility of TaskGen and CrewAI with package versions is as follows:\\\\n\\\\n1. **TaskGen**:\\\\n   - The specific versions of packages that TaskGen is compatible with are not detailed in the scraped data. However, it is mentioned that TaskGen is compatible with ChatGPT (gpt-3.5-turbo) and more advanced models like gpt-4-turbo. For robust use, it is recommended to use gpt-4-turbo and better models.\\\\n   - Installation is done via the command: `pip install taskgen-ai`.\\\\n   - The repository includes a `requirements.txt` file, which typically lists the dependencies and their versions, but the exact contents of this file are not provided in the scraped data.\\\\n\\\\n2. **CrewAI**:\\\\n   - The specific versions of packages that CrewAI is compatible with are also not detailed in the scraped data. However, it is mentioned that CrewAI works with both OpenAI and open-source models.\\\\n   - Installation is done via the command: `pip install crewai`. For additional tools, use: `pip install 'crewai[tools]'`.\\\\n   - The repository includes a `pyproject.toml` file, which typically lists the dependencies and their versions, but the exact contents of this file are not provided in the scraped data.\\\\n   - CrewAI uses `poetry` for dependency management, and the commands `poetry lock`, `poetry install`, and `poetry shell` are used for setting up the environment.\\\\n\\\\nIn summary, while the exact versions of compatible packages are not explicitly mentioned, both TaskGen and CrewAI provide installation commands and include files (`requirements.txt` for TaskGen and `pyproject.toml` for CrewAI) that specify their dependencies. Users should refer to these files in the respective repositories for detailed version information.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What version of packages are they compatible with?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c8158-7cd7-4bdd-8402-40e55bb55566",
   "metadata": {},
   "source": [
    "# LangChain Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a529f507-3a54-497d-9c0c-3e5e1c12a308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0f6992-0fb3-4124-82e2-41f8a299dabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import Agent\n",
    "agent = Agent('Math Whiz', 'Does calculations').assign_functions([add.func, multiply.func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e011a86-35f6-4922-803b-184f86c6a331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: For general tasks. Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only after task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add\\nDescription: Adds <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\",\n",
       " \"Name: multiply\\nDescription: Multiplies <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5506cd63-51c5-43e6-99b4-d4068579d7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Need to calculate 3*5+3\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Multiply 3 and 5\u001b[0m\n",
      "Calling function multiply with parameters {'a': 3, 'b': 5}\n",
      "> {'output_1': 15}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task is to calculate 3*5+3. The subtask of multiplying 3 and 5 has been completed successfully.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the assigned task, we need to add the result of multiplying 3 and 5 to 3.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add the result of multiplying 3 and 5 to 3.\u001b[0m\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task involves calculating 3*5+3.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The subtasks for multiplying 3 and 5, and adding the result to 3 have been completed. Now, the final step is to add the result of multiplying 3 and 5 to 3.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add the result of multiplying 3 and 5 to 3.\u001b[0m\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task involves calculating 3*5+3, which has been broken down into multiplying 3 and 5 to get 15, then adding 3 to the result to get 18 twice.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the previous steps have been completed, the final step is to add the result of multiplying 3 and 5 to 3 one more time to complete the calculation.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add the result of multiplying 3 and 5 to 3 one more time.\u001b[0m\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "### Auto-summarising Subtasks Completed ###\n",
      "The result of calculating 3*5+3 is 18. This is obtained by first multiplying 3 and 5 to get 15, and then adding 3 to the result.\n",
      "### End of Auto-summary ###\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The result of calculating 3*5+3 is 18. This is obtained by first multiplying 3 and 5 to get 15, and then adding 3 to the result.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The Assigned Task has been completed with the calculation of 3*5+3. No remainder is left.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The result of calculating 3*5+3 is 18. This is obtained by first multiplying 3 and 5 to get 15, and then adding 3 to the result.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Calculate 3*5+3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfcddc-b3cf-4d1c-8749-89827b901b06",
   "metadata": {},
   "source": [
    "# LangChain Community Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e866e88-8f0d-4aaf-a12e-ae7fb91dea3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wikipedia_tool(search_query: str) -> str:\n",
    "    ''' Uses search_query and returns text from wikipedia '''\n",
    "    from langchain.tools import WikipediaQueryRun\n",
    "    from langchain.utilities import WikipediaAPIWrapper\n",
    "    from langchain.agents import Tool\n",
    "\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    return wikipedia.run(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12493d87-7e25-4fab-b8d1-8d5799e3616a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Wiki Agent', 'Searches Wiki').assign_functions(wikipedia_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4cc46c-d2dc-40e0-b124-e5764d6ea058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet for the Assigned Task\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Need to search for information on LangChain using the equipped functions\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Use the wikipedia_tool function to search for information on LangChain\u001b[0m\n",
      "Calling function wikipedia_tool with parameters {'search_query': 'LangChain'}\n",
      "> {'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison â†’ house, chat â†’ cat, chien â†’\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison â†’ house, chat â†’ cat, chien â†’\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Get me information on LangChain', num_subtasks = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda84665-304f-4e22-94d9-dab271d909a1",
   "metadata": {},
   "source": [
    "# LlamaIndex Function Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7cad1e-abe9-4f13-9478-ccabd02338e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Usfeful for getting the weather for a given location.\"\"\"\n",
    "    return 'Sunny'\n",
    "    ...\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    # async_fn=aget_weather,  # optional!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5dbfa06-9849-4864-b775-094bcf98e401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Weather Agent', 'Returns the Weather').assign_functions(tool.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "366387df-b36c-44a1-b45a-fa6cd2b58fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: For general tasks. Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only after task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: get_weather\\nDescription: Usfeful for getting the weather for a given <location: str>.\\nInput: ['location']\\nOutput: {'output_1': 'str'}\\n\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29544561-a87c-4190-ad87-9d9f4c3cb235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Need to get the weather for Miami\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Get the weather for Miami\u001b[0m\n",
      "Calling function get_weather with parameters {'location': 'Miami'}\n",
      "> {'output_1': 'Sunny'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The weather for Miami has been retrieved as Sunny\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The weather information has been successfully obtained. No further action is needed.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Sunny'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What is the weather in Miami?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
